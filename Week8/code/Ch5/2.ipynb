{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python36964bit9e4a341e6cd34e1fa5fa544aa3e2bd6d",
   "display_name": "Python 3.6.9 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "Using TensorFlow backend.\nWARNING:tensorflow:From /usr/lib/python3/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\nInstructions for updating:\nIf using Keras pass *_constraint arguments to layers.\nWARNING:tensorflow:From /usr/lib/python3/dist-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n\nFound 2000 images belonging to 2 classes.\nFound 1000 images belonging to 2 classes.\nWARNING:tensorflow:From /usr/lib/python3/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.where in 2.0, which has the same broadcast rule as np.where\nWARNING:tensorflow:From /usr/lib/python3/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n\nEpoch 1/30\n1000/1000 [==============================] - 104s 104ms/step - loss: 0.4741 - acc: 0.7666 - val_loss: 0.3153 - val_acc: 0.8690\nEpoch 2/30\n1000/1000 [==============================] - 101s 101ms/step - loss: 0.3637 - acc: 0.8340 - val_loss: 0.2058 - val_acc: 0.8910\nEpoch 3/30\n1000/1000 [==============================] - 102s 102ms/step - loss: 0.3316 - acc: 0.8518 - val_loss: 0.3078 - val_acc: 0.8940\nEpoch 4/30\n1000/1000 [==============================] - 102s 102ms/step - loss: 0.3151 - acc: 0.8618 - val_loss: 0.1218 - val_acc: 0.9020\nEpoch 5/30\n1000/1000 [==============================] - 101s 101ms/step - loss: 0.2992 - acc: 0.8703 - val_loss: 0.2625 - val_acc: 0.9030\nEpoch 6/30\n1000/1000 [==============================] - 102s 102ms/step - loss: 0.2915 - acc: 0.8733 - val_loss: 0.4061 - val_acc: 0.9000\nEpoch 7/30\n1000/1000 [==============================] - 100s 100ms/step - loss: 0.2854 - acc: 0.8759 - val_loss: 0.2263 - val_acc: 0.9060\nEpoch 8/30\n1000/1000 [==============================] - 99s 99ms/step - loss: 0.2787 - acc: 0.8822 - val_loss: 0.3217 - val_acc: 0.9040\nEpoch 9/30\n1000/1000 [==============================] - 97s 97ms/step - loss: 0.2741 - acc: 0.8816 - val_loss: 0.1741 - val_acc: 0.9000\nEpoch 10/30\n1000/1000 [==============================] - 98s 98ms/step - loss: 0.2622 - acc: 0.8895 - val_loss: 0.0649 - val_acc: 0.9070\nEpoch 11/30\n1000/1000 [==============================] - 98s 98ms/step - loss: 0.2629 - acc: 0.8907 - val_loss: 0.1156 - val_acc: 0.9070\nEpoch 12/30\n1000/1000 [==============================] - 99s 99ms/step - loss: 0.2594 - acc: 0.8911 - val_loss: 0.1573 - val_acc: 0.9070\nEpoch 13/30\n1000/1000 [==============================] - 98s 98ms/step - loss: 0.2586 - acc: 0.8908 - val_loss: 0.2280 - val_acc: 0.9030\nEpoch 14/30\n1000/1000 [==============================] - 99s 99ms/step - loss: 0.2559 - acc: 0.8922 - val_loss: 0.1493 - val_acc: 0.9060\nEpoch 15/30\n1000/1000 [==============================] - 98s 98ms/step - loss: 0.2530 - acc: 0.8948 - val_loss: 0.9806 - val_acc: 0.9060\nEpoch 16/30\n1000/1000 [==============================] - 100s 100ms/step - loss: 0.2477 - acc: 0.8978 - val_loss: 0.3552 - val_acc: 0.9000\nEpoch 17/30\n1000/1000 [==============================] - 100s 100ms/step - loss: 0.2447 - acc: 0.8977 - val_loss: 0.0891 - val_acc: 0.9060\nEpoch 18/30\n1000/1000 [==============================] - 99s 99ms/step - loss: 0.2432 - acc: 0.8990 - val_loss: 0.2058 - val_acc: 0.9060\nEpoch 19/30\n1000/1000 [==============================] - 99s 99ms/step - loss: 0.2413 - acc: 0.8988 - val_loss: 0.2291 - val_acc: 0.9050\nEpoch 20/30\n1000/1000 [==============================] - 102s 102ms/step - loss: 0.2446 - acc: 0.8980 - val_loss: 0.2251 - val_acc: 0.9040\nEpoch 21/30\n1000/1000 [==============================] - 101s 101ms/step - loss: 0.2373 - acc: 0.9032 - val_loss: 0.2261 - val_acc: 0.9080\nEpoch 22/30\n1000/1000 [==============================] - 101s 101ms/step - loss: 0.2360 - acc: 0.9035 - val_loss: 0.1681 - val_acc: 0.9010\nEpoch 23/30\n1000/1000 [==============================] - 101s 101ms/step - loss: 0.2378 - acc: 0.9030 - val_loss: 0.1852 - val_acc: 0.9080\nEpoch 24/30\n1000/1000 [==============================] - 100s 100ms/step - loss: 0.2311 - acc: 0.9061 - val_loss: 0.2460 - val_acc: 0.9050\nEpoch 25/30\n1000/1000 [==============================] - 100s 100ms/step - loss: 0.2284 - acc: 0.9073 - val_loss: 0.5117 - val_acc: 0.9060\nEpoch 26/30\n1000/1000 [==============================] - 101s 101ms/step - loss: 0.2328 - acc: 0.9056 - val_loss: 0.4439 - val_acc: 0.9030\nEpoch 27/30\n1000/1000 [==============================] - 101s 101ms/step - loss: 0.2256 - acc: 0.9071 - val_loss: 0.0947 - val_acc: 0.9040\nEpoch 28/30\n1000/1000 [==============================] - 100s 100ms/step - loss: 0.2274 - acc: 0.9086 - val_loss: 0.4084 - val_acc: 0.9040\nEpoch 29/30\n1000/1000 [==============================] - 102s 102ms/step - loss: 0.2210 - acc: 0.9108 - val_loss: 0.0793 - val_acc: 0.9080\nEpoch 30/30\n1000/1000 [==============================] - 101s 101ms/step - loss: 0.2222 - acc: 0.9115 - val_loss: 0.1254 - val_acc: 0.9050\n"
    }
   ],
   "source": [
    "from keras.applications import VGG16\n",
    "import os\n",
    "from keras import models, layers, optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#setting the paths\n",
    "baseDir = '/home/chen/LiChiChang/2020SpringThesis/dataset/CatDog/shrink'\n",
    "trainDir = os.path.join(baseDir, 'train')\n",
    "validationDir = os.path.join(baseDir, 'validation')\n",
    "testDir = os.path.join(baseDir, 'test')\n",
    "\n",
    "#the pretrain model from open sources\n",
    "conv_base = VGG16(weights='imagenet',include_top=False,input_shape=(150, 150, 3))\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "conv_base.trainable = False\n",
    "\n",
    "trainDatagen = ImageDataGenerator(rescale=1./255, rotation_range=40, width_shift_range=0.2, height_shift_range=0.2, zoom_range=0.2, horizontal_flip=True, fill_mode='nearest')\n",
    "trainGenerator = trainDatagen.flow_from_directory(trainDir, target_size=(150,150), batch_size=20, class_mode='binary')\n",
    "\n",
    "validationDatagen = ImageDataGenerator(rescale=1./255)#validation and test dataset shouldn't be augmented\n",
    "validationGenerator = validationDatagen.flow_from_directory(validationDir, target_size=(150,150), batch_size=20, class_mode='binary')\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizers.RMSprop(lr=2e-5), metrics=['acc'])\n",
    "\n",
    "history = model.fit_generator(trainGenerator, steps_per_epoch=1000, epochs=30, validation_data=validationGenerator, validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot and summary\n",
    "print(\"the VGG model:\")\n",
    "conv_base.summary()\n",
    "print(\"my model:\")\n",
    "model.summary()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "validationAcc = history.history['val_acc']\n",
    "\n",
    "loss = history.history['loss']\n",
    "validationLoss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc)+1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='training acc')\n",
    "plt.plot(epochs, validationAcc, 'b', label='validation acc')\n",
    "plt.title('training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='training loss')\n",
    "plt.plot(epochs, validationLoss, 'b', label='validation loss')\n",
    "plt.title('training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}