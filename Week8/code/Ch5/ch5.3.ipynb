{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python36864bitc9f813a56981486d89d460fa6421c0c5",
   "display_name": "Python 3.6.8 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import VGG16\n",
    "conv_base = VGG16(weights='imagenet',include_top=False,input_shape=(150, 150, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "baseDir = '/home/chen/LiChiChang/2020SpringThesis/dataset/CatDog/shrink'\n",
    "trainDir = os.path.join(baseDir, 'train')\n",
    "validationDir = os.path.join(baseDir, 'validation')\n",
    "testDir = os.path.join(baseDir, 'test')\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "batchSize = 20\n",
    "\n",
    "def extractFeature(dir, sampleCount):\n",
    "    features = np.zeros(shape=(sampleCount,4,4,512))\n",
    "    labels = np.zeros(shape=(sampleCount))\n",
    "    generator = datagen.flow_from_directory(dir, target_size=(150,150), batch_size=batchSize, class_mode='binary')\n",
    "    i = 0\n",
    "    for inputsBatch, labelsBatch in generator:\n",
    "        featuresBatch = conv_base.predict(inputsBatch)\n",
    "        features[i * batchSize: (i + 1)*batchSize] = featuresBatch\n",
    "        labels[i * batchSize: (i + 1)*batchSize] = labelsBatch\n",
    "        i += 1\n",
    "        if i*batchSize >= sampleCount:\n",
    "            break\n",
    "    return features, labels\n",
    "\n",
    "trainFeatures, trainLabels = extractFeature(trainDir, 2000)\n",
    "validationFeatures, validationLabels = extractFeature(validationDir, 1000)\n",
    "testFeatures, testLabels = extractFeature(testDir, 1000)\n",
    "\n",
    "trainFeatures = np.reshape(trainFeatures, (2000, 4*4*512))\n",
    "validationFeatures = np.reshape(validationFeatures, (1000, 4*4*512))\n",
    "testFeatures = np.reshape(testFeatures, (1000, 4*4*512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models, layers, optimizers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(256, activation='relu', input_dim=4*4*512))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=2e-5), loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "history = model.fit(trainFeatures, trainLabels, epochs=30, batch_size=20, validation_data=(validationFeatures,validationLabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "validationAcc = history.history['val_acc']\n",
    "\n",
    "loss = history.history['loss']\n",
    "validationLoss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc)+1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='training acc')\n",
    "plt.plot(epochs, validationAcc, 'b', label='validation acc')\n",
    "plt.title('training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='training loss')\n",
    "plt.plot(epochs, validationLoss, 'b', label='validation loss')\n",
    "plt.title('training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Listing 5.20\n",
    "Combine the 2 models into 1\n",
    "'''\n",
    "\n",
    "from keras import models, layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()\n",
    "print('before freezing the convnet:' , len(model.trainable_weights))\n",
    "conv_base.trainable = False\n",
    "print('after freezing the convnet:' , len(model.trainable_weights))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "\n",
    "trainDatagen = ImageDataGenerator(rescale=1./255, rotation_range=40, width_shift_range=0.2, height_shift_range=0.2, zoom_range=0.2, horizontal_flip=True, fill_mode='nearest')\n",
    "trainGenerator = trainDatagen.flow_from_directory(trainDir, target_size=(150,150), batch_size=20, class_mode='binary')\n",
    "\n",
    "validationDatagen = ImageDataGenerator(rescale=1./255)#validation and test dataset shouldn't be augmented\n",
    "validationGenerator = validationDatagen.flow_from_directory(validationDir, target_size=(150,150), batch_size=20, class_mode='binary')\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizers.RMSprop(lr=2e-5), metrics=['acc'])\n",
    "\n",
    "history = model.fit_generator(trainGenerator, steps_per_epoch=100, epochs=30, validation_data=validationGenerator, validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "validationAcc = history.history['val_acc']\n",
    "\n",
    "loss = history.history['loss']\n",
    "validationLoss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc)+1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='training acc')\n",
    "plt.plot(epochs, validationAcc, 'b', label='validation acc')\n",
    "plt.title('training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='training loss')\n",
    "plt.plot(epochs, validationLoss, 'b', label='validation loss')\n",
    "plt.title('training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base.trainable = True\n",
    "set_trainable = False\n",
    "\n",
    "for layer in conv_base.layers:\n",
    "    if layer.name == 'block5_conv1':\n",
    "        set_trainable == True\n",
    "    layer.trainable = set_trainable\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizers.RMSprop(lr=1e-5), metrics=['acc'])\n",
    "\n",
    "history = model.fit_generator(trainGenerator, steps_per_epoch=100, epochs=100, validation_data=validationGenerator, validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-7d8983c16d96>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "def smooth_curve(points, factor=0.8):\n",
    "    smoothed_points = []\n",
    "    for point in points:\n",
    "        if smoothed_points:\n",
    "            previous = smoothed_points[-1]\n",
    "            smoothed_points.append(previous * factor + point * (1 - factor))\n",
    "        else:\n",
    "            smoothed_points.append(point)\n",
    "    return smoothed_points\n",
    "plt.plot(epochs,smooth_curve(acc), 'bo', label='Smoothed training acc')\n",
    "plt.plot(epochs,smooth_curve(val_acc), 'b', label='Smoothed validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs,smooth_curve(loss), 'bo', label='Smoothed training loss')\n",
    "plt.plot(epochs,smooth_curve(val_loss), 'b', label='Smoothed validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}