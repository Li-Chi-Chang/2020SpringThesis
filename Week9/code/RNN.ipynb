{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python36964bit9e4a341e6cd34e1fa5fa544aa3e2bd6d",
   "display_name": "Python 3.6.9 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Textbook code\n",
    "\n",
    "Ch 6 of Textbook\n",
    "\n",
    "Student: Li-Chi Chang\n",
    "\n",
    "Professor: Zesheng Chen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word-level one-hot encoding (toy example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n  [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n  [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n  [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n  [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n  [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n\n [[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n  [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n  [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n  [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "samples = ['The cat sat on the mat.', 'The dog ate my homework.']\n",
    "token_index = {}\n",
    "for sample in samples:\n",
    "    for word in sample.split():\n",
    "        if word not in token_index:\n",
    "            token_index[word] = len(token_index) + 1\n",
    "max_length = 10\n",
    "results = np.zeros(shape=(len(samples),max_length,max(token_index.values()) + 1))\n",
    "for i, sample in enumerate(samples):\n",
    "    for j, word in list(enumerate(sample.split()))[:max_length]:\n",
    "        index = token_index.get(word)\n",
    "        results[i, j, index] = 1.\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Character-level one-hot encoding (toy example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[[1. 1. 1. ... 1. 1. 1.]\n  [1. 1. 1. ... 1. 1. 1.]\n  [1. 1. 1. ... 1. 1. 1.]\n  ...\n  [0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]]\n\n [[1. 1. 1. ... 1. 1. 1.]\n  [1. 1. 1. ... 1. 1. 1.]\n  [1. 1. 1. ... 1. 1. 1.]\n  ...\n  [0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]]]\n"
    }
   ],
   "source": [
    "import string\n",
    "samples = ['The cat sat on the mat.', 'The dog ate my homework.']\n",
    "characters = string.printable\n",
    "token_index = dict(zip(range(1, len(characters) + 1), characters))\n",
    "max_length = 50\n",
    "results = np.zeros((len(samples), max_length, max(token_index.keys()) + 1))\n",
    "for i, sample in enumerate(samples):\n",
    "    for j, character in enumerate(sample):\n",
    "        index = token_index.get(character)\n",
    "        results[i, j, index] = 1.\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Keras for word-level one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Using TensorFlow backend.\n[[1, 2, 3, 4, 1, 5], [1, 6, 7, 8, 9]]\n[[0. 1. 1. ... 0. 0. 0.]\n [0. 1. 0. ... 0. 0. 0.]]\nFound 9 unique tokens.\n"
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "samples = ['The cat sat on the mat.','The dog ate my homework.']\n",
    "\n",
    "tokenizer = Tokenizer(num_words=1000)\n",
    "tokenizer.fit_on_texts(samples)\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(samples)\n",
    "\n",
    "oneHotResult = tokenizer.texts_to_matrix(samples, mode='binary')\n",
    "\n",
    "wordIndex = tokenizer.word_index\n",
    "\n",
    "print(sequences)\n",
    "print(oneHotResult)\n",
    "\n",
    "print('Found %s unique tokens.' % len(wordIndex))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word-level one-hot encoding with hashing trick (toy example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
    }
   ],
   "source": [
    "samples = ['The cat sat on the mat.', 'The dog ate my homework.']\n",
    "\n",
    "dimensionality = 1000\n",
    "max_length = 10\n",
    "\n",
    "results = np.zeros((len(samples), max_length, dimensionality))\n",
    "for i, sample in enumerate(samples):\n",
    "    for j, word in list(enumerate(sample.split()))[:max_length]:\n",
    "        index = abs(hash(word)) % dimensionality\n",
    "        results[i, j, index] = 1.\n",
    "\n",
    "print(results[0,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word embedding technique\n",
    "\n",
    "Word embeddings are meant to map human language into a geometric space.\n",
    "\n",
    "## Instantiating an Embedding layer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding\n",
    "embedding_layer = Embedding(1000, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras import preprocessing\n",
    "max_features = 10000\n",
    "maxlen = 20\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "x_train = preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = preprocessing.sequence.pad_sequences(x_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:From /usr/lib/python3/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\nInstructions for updating:\nIf using Keras pass *_constraint arguments to layers.\nWARNING:tensorflow:From /usr/lib/python3/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.where in 2.0, which has the same broadcast rule as np.where\nModel: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_2 (Embedding)      (None, 20, 8)             80000     \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 160)               0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 1)                 161       \n=================================================================\nTotal params: 80,161\nTrainable params: 80,161\nNon-trainable params: 0\n_________________________________________________________________\nWARNING:tensorflow:From /usr/lib/python3/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n\nTrain on 20000 samples, validate on 5000 samples\nEpoch 1/10\n20000/20000 [==============================] - 3s 145us/step - loss: 0.6727 - acc: 0.6187 - val_loss: 0.6308 - val_acc: 0.6848\nEpoch 2/10\n20000/20000 [==============================] - 3s 135us/step - loss: 0.5567 - acc: 0.7481 - val_loss: 0.5364 - val_acc: 0.7244\nEpoch 3/10\n20000/20000 [==============================] - 3s 135us/step - loss: 0.4700 - acc: 0.7832 - val_loss: 0.5062 - val_acc: 0.7384\nEpoch 4/10\n20000/20000 [==============================] - 3s 135us/step - loss: 0.4234 - acc: 0.8098 - val_loss: 0.4990 - val_acc: 0.7450\nEpoch 5/10\n20000/20000 [==============================] - 3s 134us/step - loss: 0.3910 - acc: 0.8290 - val_loss: 0.4981 - val_acc: 0.7486\nEpoch 6/10\n20000/20000 [==============================] - 2s 123us/step - loss: 0.3631 - acc: 0.8458 - val_loss: 0.5032 - val_acc: 0.7472\nEpoch 7/10\n20000/20000 [==============================] - 3s 134us/step - loss: 0.3380 - acc: 0.8580 - val_loss: 0.5101 - val_acc: 0.7482\nEpoch 8/10\n20000/20000 [==============================] - 3s 134us/step - loss: 0.3148 - acc: 0.8709 - val_loss: 0.5166 - val_acc: 0.7484\nEpoch 9/10\n20000/20000 [==============================] - 3s 134us/step - loss: 0.2935 - acc: 0.8815 - val_loss: 0.5264 - val_acc: 0.7466\nEpoch 10/10\n20000/20000 [==============================] - 3s 135us/step - loss: 0.2741 - acc: 0.8921 - val_loss: 0.5377 - val_acc: 0.7436\n"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense\n",
    "model = Sequential()\n",
    "model.add(Embedding(10000, 8, input_length=maxlen))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "model.summary()\n",
    "history = model.fit(x_train, y_train,epochs=10,batch_size=32,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "25000\n20\n25000\n"
    }
   ],
   "source": [
    "print(len(x_train))\n",
    "print(len(x_train[0]))\n",
    "print(len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "imdb_dir = '/home/chen/LiChiChang/2020SpringThesis/dataset/IMDB/aclImdb'\n",
    "train_dir = os.path.join(imdb_dir, 'train')\n",
    "labels = []\n",
    "texts = []\n",
    "for label_type in ['neg', 'pos']:\n",
    "    dir_name = os.path.join(train_dir, label_type)\n",
    "    for fname in os.listdir(dir_name):\n",
    "        if fname[-4:] == '.txt':\n",
    "            f = open(os.path.join(dir_name, fname))\n",
    "            texts.append(f.read())\n",
    "            f.close()\n",
    "            if label_type == 'neg':\n",
    "                labels.append(0)\n",
    "            else:\n",
    "                labels.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "ssed it \\x96 they're hot for each other once again. Only this time Sherry's spinster sister, Connie (Harriet Hillard) threatens the whole fine romance by falling for Bake's robust seafaring buddy, Bilge Smith (Randolph Scott); a sort of use 'em up and toss 'em out kind of guy, thus forcing Sherry to reconsider her opinion of all sailors in general. Irving Berlin lends immeasurable class to the proceedings with his classic, classy score, including standards 'Let Yourself Go', 'I'm Putting All My Eggs in One Basket' and 'Let's Face the Music and Dance;' the latter a divinely inspired skit about suicide that turns into another immediately recognizable and thoroughly sublime pas deux for Fred and Ginger. <br /><br />The transfer on 'Follow The Fleet' is a tad weaker. The gray scale remains nicely balanced but now it's a tad thick looking with not nearly as much tonal variation as the previous titles. Grain is still present. So are age related artifacts. Once you've settled into to the slightly dense and sometimes more softly focused image quality, the overall impression is more than acceptable for a film of this vintage. The audio is Mono but very nicely balanced. Extras include a featurette, theatrical trailer and short subject, but oddly \\x96 no audio commentary. Considering the importance of this film in the overall canon of Astaire/Rogers this is an uncharacteristic oversight from Warner Home Video.\", '\"That \\'70s Show\" is definitely the funniest show currently on TV. I started watching it about two and a half years ago, and as soon as I saw it I could tell it was a great show. I like all the characters, but my personal favorites are Fez and Kelso. Leo was also an awesome character while he was there, I really hope he comes back because he\\'s hilarious. It\\'s classic when Fez goes \"you son of a bitch!\", and when Kelso yells \"burn!\", that always makes me laugh. They are both great characters and always have something funny to say. Jackie being hot is just another reason to watch the show; she started out being really good looking but damn, somewhere around season 5-6 she just got Really hot. I\\'ve seen most of the episodes more than once, some like 10 times, and there still hilarious. This is one of the few shows that I can watch over and over and still laugh at just as much as I did the first time I saw it. The cast is classic; almost everyone is funny, where with many shows there are only a few funny characters. I will be sad to see this show end next year, but it will be going off the air as one of the best shows ever.', '...this is, above all else, the typical Crown International Pictures drive-in (read \"passion pit\") programmer. The 1975 Sammy Johns hit record \"Chevy Van\" is heard repeatedly on the soundtrack (this movie has even been reissued with the title CHEVY VAN), despite the film\\'s title vehicle being a Dodge. Danny DeVito makes only six minutes of on-screen appearance, but countless VHS reissues falsely credit him as the star of the flick. The movie is a comparatively sexist morality tale -- will Bobby find sexual satisfaction through the one-night-stand his customised van facilitates, or must he wait until Tina, the girl of his dreams, gives him the time of day? Still, it is representative of the prevailing carnal dream of male American high schoolers of the time, and on that basis alone THE VAN has, almost in spite of itself, become an artifact of the period that must be referenced in any honest retrospective of the period\\'s popular American cinema...', '(SPOILERS IN FIRST PARAGRAPH) This movie\\'s anti-German sentiment seems painfully dated now, but it\\'s a brilliant example of great war-time propaganda. It was made back when Cecil B. DeMille was still a great director. (Ignore all his later Best Picture Academy Awards; he never made a very good sound film.) This movie lacks the comedy of most of Pickford\\'s other films, and really it was DeMille\\'s movie, not Pickford\\'s. The vilification of the Germans can be compared to the way \"The Patriot\" of 2000 did the same to the British. The only good German in the film was a reluctant villain who had the ironic name of Austreheim. They even had Pickford take an ill-fated trip on a luxury ship that gets torpedoed by a German submarine. So what\\'ll get the Americans more stirred up to war? The sinking of the Lusitania, or watching America\\'s favorite Canadian import sinking in it? All throughout the film DeMille runs his protagonist from one kind of horrible calamity to another, barely escaping death, hypothermia, depravity, rape, execution, and explosions that go off in just the right place to keep her unharmed. The way she is saved from a firing squad is no more believable than the way the humans in \"Jurassic Park\" were ultimately rescued from the velociraptors. If I was any more gullible to such propaganda I would punish myself for having a part-German ancestry. <br /><br />Was it a good film? Aside from a humorous running gag about Americans abroad thinking they\\'re untouchable \\x96 that was apparently a joke even back then \\x96 you might not be entertained. You\\'ll find it more than a little melodramatic, and obviously one-sided, but the first thing that came to my mind after watching it is that it was years before Potemkin\\'s false portrayal of a massacre revolutionized the language of cinema as well as a movie\\'s potential for propaganda. It made me wonder: what became of Cecil B. DeMille? Somewhere between the advent of sound and \"The Greatest Show on Earth\" he seemed to lose his ambition. Ben Hur looked expensive, but not ambitious. In a sentence, this movie is for 1) Film historians, 2) Silent Film Buffs, 3) Mary Pickford fans, or 4) DeMille fans, if such a person exists.', \"This Schiffer guy is a real genius! The movie is of excellent quality and both entertaining and educating.<br /><br />I didn't know what a weather girl was before I learned it here.\", 'This whimsical film had the misfortune of being released at the same time of the highly popular \"Amelie\", both having the wonderful Audrey Tautou playing the central role. Laurent Firode, the talented director made one of the most enjoyable films that have come out of France in recent memory.<br /><br />The film deals with chance, as its English title indicates. The French title makes reference at how butterflies wings can create chaos over the Atlantic as they fly, as well as hurricanes in the Pacific, something not to be believed just by looking at these colorful insects. From the start, the director interlaces all the characters one sees in the film and how each has a connection to the other, something that is hard to imagine, but in the film\\'s context seems to work well.<br /><br />A chance meeting at the metro sets the tone for the film. Irene, who is going to work, is asked by the woman sitting opposite her to tell her what her Zodiac sign is and proceeds to read from her paper. Irene, it seems will cross paths and will find her soul mate that same day. After Irene leaves the train, the quiet young man seated next to the woman tells her he has the same birth date as Irene. It seems they are destined to one another from the start, but alas, they will not reconnect until the last frame of the film.<br /><br />Audrey Tautou is wonderful as Irene. Faudel, who plays Younes, doesn\\'t have a lot to do until the end, but he shows he has a presence and plays well his part. The talented young cast makes a valuable contribution to the success of the film, which is as light as butterfly wings.<br /><br />We look forward to future films by Laurent Firode because he appears to be a director with the heart in the right place and an ear to the way humans are connected.', \"Alain Resnais films are uncanny in the way that they aren't really edited for continuity, but instead the shot seems to finish right where a memory has edited. Love unto Death is at times a quiet existential drama and a roundly creative magical realist movie, and either way treats the audience to a whole new aspect of the Eros/Thanatos relationship... or perhaps creates a new relationship, that of Agape/Thanatos.<br /><br />The beginning is like a bizarre surrealist horror movie. A woman desperately runs around the house while a man lays dying in his bed--did she kill him, or what happened? Soon that tension is dissolved as a doctor arrives and pronounces him dead, but from there a newer, stranger drama begins: the man wakes up, and after being dead the woman and man fall in love to actually quite tragic consequences. Meanwhile, their friends, who are both priests, watch on and submit their own debate into the nature of love, faith, and devotion.<br /><br />Resnais always seems to have some device to make these sorts of narratives work, and what's so amazing about his films is that those devices always work. In this case, Resnais intercuts the scenes with shots of snow falling to an arousing orchestral score, which fades off and bleeds into the subsequent shots that continue the story. Trapped in this elegiac aside periodically, the film develops a rhythm not too unlike an epic poem, and I got strange flashbacks to Dante's Divine Comedy from this one, despite the lack of direct reference within the movie. Resnais is known as a very poetic filmmaker but this extends past just the cinepoem structure to something that forces a degree of introspection in the viewer, which has the possibility to bring to surface some odd recollections. Memory-narrative, Resnais creates.<br /><br />--PolarisDiB\", \"This is a better than average silent movie and it's still well worth seeing if you are a fan of the silents. However, if you aren't yet a fan of the genre, I suggest you try a few other films before watching this one. That's because the plot just seems pretty old fashioned and difficult to believe in spots. But, despite this, it's still a good film and kept my interest.<br /><br />A nice lady unfortunately hooked up with the wrong man and ran away to marry him. The film starts five years later after she has come to realize that he is really a brutal thief. Despite this, she tries to make the best of it and not dwell on how good life had been before this jerk came into her life. However, the rent is due and there's no money, so the lady is forced to look for work. She becomes a personal seamstress for a rich lady whose husband is trying to swing a business deal. Unfortunately, the lady who they were trying to hook up a potential client with for a dinner party can't make it and the seamstress is paid handsomely to be the man's date. Well, like Cinderella, she cleans up pretty well and the man is infatuated with her! What to do now--given that she is actually married and the new fella wants to marry her?! Well, see the movie yourself to see how it's all resolved. I DIDN'T like how they handled the husband, as it seemed awfully predictable and clich√©d. However, once he was out of the way, I do admire how the film also DIDN'T give up a by-the-numbers finale and left the film with a few loose ends.<br /><br />All in all, a very good film worth seeing, but certainly not great.\", 'I saw this pilot when it was first shown, and I\\'m sure countless \"Spirit\" fans hate it, because, like Batman, the Green Hornet etc., it took the character in the direction of \"camp\". But I evidently never got enough of Batman, because I thought it was entertaining, in some of the same ways as that show. There are two parts that stay with me. First, when Denny\\'s partner has been fatally wounded, and he makes a dramatic speech about how he always stood for the law, and obeying the exact letter of it. Then, he says something like, \"Boy, was I stupid!\" Which is his way of telling Denny to become a vigilante instead, which he does (though the TV Batman kind). Then, there\\'s the scene where he tries to seduce the villainess into letting him go by kissing her, but she isn\\'t fooled, because he\\'s too honest to kiss her convincingly ! This was a great example of \"camp\", that was also \"underplayed\", by both the actor and actress.', \"Looking at some of the negative posts, you really have to wonder what some people do for fun....<br /><br />I was lucky enough to see the film during its all-too-brief theatrical run. The audience laughed its heads off. I'm watching a tape of it as I type and it's still dang funny!<br /><br />It's also got a sweet side, with unexpected turns of genuine pathos. The late, great Royal Dano is especially effective as the lonely, down-on-his-luck farmer Wrenchmuller. Ariana Richards and J.J. Anderson are great as the lead kids. And the actors in the Martian suits, although limited to mime, do a great job<br /><br />Another thing to look for is the background details. The film is full of homages, pastiches, and references to other SF and fantasy films. Take a look at the Martian costumes next time. One of them is wearing a Marty McFly costume, another is a Ghostbuster, a third is in a House Atreides uniform, and a fourth is wearing a Last Starfighter flightsuit.\", \"FUTZ is the only show preserved from the experimental theatre movement in New York in the 1960s (the origins of Off Off Broadway). Though it's not for everyone, it is a genuinely brilliant, darkly funny, even more often deeply disturbing tale about love, sex, personal liberty, and revenge, a serious morality tale even more relevant now in a time when Congress wants to outlaw gay marriage by trashing our Constitution. The story is not about being gay, though -- it's about love and sex that don't conform to social norms and therefore must be removed through violence and hate. On the surface, it tells the story of a man who falls in love with a pig, but like any great fable, it's not really about animals, it's about something bigger -- stifling conformity in America.<br /><br />The stage version won international acclaim in its original production, it toured the U.S. and Europe, and with others of its kind, influenced almost all theatre that came after it. Luckily, we have preserved here the show pretty much as it was originally conceived, with the original cast and original director, Tom O'Horgan (who also directed HAIR and Jesus Christ Superstar on Broadway).<br /><br />This is not a mainstream, easy-to-take, studio film -- this is an aggressive, unsettling, glorious, deeply emotional, wildly imaginative piece of storytelling that you'll never forget. And it just might change the way you see the world...\", \"This film, I thought, was the great journey that Forrest Gump should have been. It's a rare treat to watch a cable movie in the middle of the day and come across a foreign film that is done so well. This film is very well acted, and I strongly suggest it to anyone who can take sub-titles.\", \"BSG is one of my all time favourite TV series. I was lucky enough to start watching it as the series came to it's final season. It was a marathon from start to finish for me and what an incredible ride it was! <br /><br />As soon as I noticed the pilot on Hulu I knew exactly what I was in for just by the title - Caprica! Although, some things don't add up when you compare both series it is still beautifully executed. There were no mention about the holobands in Battlestar Galactica or the mention of virtual worlds but maybe I haven't got far enough into the series for them to explain why.<br /><br />I recommend this show to anyone who loves the universe, technology, and alternate fantasies of our world. This show is very interesting and will have you wanting to watch more!\", '\"Der Todesking\"-Jorg Buttgereit\\'s second full-length feature film(the first one was notorious \"Nekromantik\")has no central character or characters,but instead thematic continuity in the act of suicide.Divided into days of the week,it comprises of a series of set-pieces,each of which featuring the self-destruction of a complete stranger.Yes,the production values are low and it\\'s disturbing,but in many ways \"Der Todesking\" is extremely effective.It makes you think which is sometimes more important than pure entertainment.Unlike the other Buttgereit\\'s works it isn\\'t very gory,but there are some unpleasant images like castration scene in the Tuesday episode,a decomposing corpse and various acts of suicide.The last(Sunday)episode is so depressing and full of pain!-just amazing if you want my opinion.10 out of 10-check out this post-modernism shocker!Disturbing art in the purest form!', 'This silly movie is really fun for the younger audiences. Its heros are a couple of dud detectives whose sophomoric attitudes lead them down some very silly roads. Chasing the big murder case, you will see these detectives go to every length to solve the crime. No nudity, but lots of sexual implication, slapstick silliness...everything adolescents go for. Low budget, but very entertaining. Definite cult classic potential.', \"I don't think this movie is for everyone. But I saw it this weekend in Seattle and I thought it was so funny. I haven't laughed that hard during a movie in long time. I thought the entire cast did a great job. You will find yourself laughing from the first moment through the very last scene. I suspect some moviegoers (especially the ones who take themselves WAY too seriously) will be turned off by this brand of humor. Not me. The movie was a real surprise. And the entire theater was rolling with laughter throughout the showing I went to which makes me think that a lot of people enjoyed themselves and were happy to have a good time at the movies for a change. I cannot wait to see it again! If you're in the mood to LOL then this is for you. Funny funny funny funny!\", \"I originally saw this film years ago during Cinemax Friday after dark series(back when the cable box was built like a keyboard),and it intrigued me. Even though there is a pointless aspect to the film it is well acted.The performances of Depardieu & Dewaere are very enjoyable.They have a good chemistry together & Miou-Miou makes a pink fur look breathtaking.A movie like this probably wouldn't be made in these politically correct times(at least not in the US), since it seems to sensationalize things like violence,robbery,& casual sex. This movie proves that with a talented cast & also talented directing a good movie is a good movie no matter the subject.It saddened me to find out Patrick Dewaere committed suicide & in the near future I,ll will check him out with Depardieu & Miou-Miou in Get Out Your Hankerchief.\", 'Men of Honor has many great aspects to it. Good action sequences, plenty of \"feel good\" scenes, a good musical score, but the part that really makes the movie is the great acting. Mostly by Robert Deniro. The story of Men of Honor is focused about Carl Brashear played by Cuba Gooding Jr. who wants to be the first African American deep sea diver in the navy. It chronicles his rough struggle from being a poor farmer to getting into diving school and even further. It is a good story, but it seems like it has been done many times before. A person, against all of the odds, won\\'t give up until they accomplish their goals that they set for some sentimental reason many years ago. It could happen, but a lot of the struggles the Brashear faces in the movie are questionable including the C.O. of the diving school tampering with his final test. However, all of that is made up for the scene when Robert Deniro finally enters the movie. Deniro plays Mater Chief Sunday who is the teacher at the diving school Brashear is attending. As soon as Deniro come in he omits this vibe of extreme arrogance that you can\\'t hate unless you have incredible wilpower. Before the movie ends, Deniro gives off multiple speeches that would have you laughing at how cool he is but you are too stunned at the way he punches them out. In the end you must doubt some of the aspects of the film, but admit it, if it was all the truth, it would have you snoozing it your seat by the first twenty minutes.']\n25000\n"
    }
   ],
   "source": [
    "print(labels)\n",
    "print(texts)\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Found 88582 unique tokens.\nShape of data tensor: (25000, 100)\nShape of label tensor: (25000,)\n"
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "maxlen = 100\n",
    "training_samples = 200\n",
    "validation_samples = 10000\n",
    "max_words = 10000\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "data = pad_sequences(sequences, maxlen=maxlen)\n",
    "labels = np.asarray(labels)\n",
    "print('Shape of data tensor:', data.shape)\n",
    "print('Shape of label tensor:', labels.shape)\n",
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "labels = labels[indices]\n",
    "x_train = data[:training_samples]\n",
    "y_train = labels[:training_samples]\n",
    "x_val = data[training_samples: training_samples + validation_samples]\n",
    "y_val = labels[training_samples: training_samples + validation_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Found 400000 word vectors.\n"
    }
   ],
   "source": [
    "glove_dir = '/home/chen/LiChiChang/2020SpringThesis/dataset/glove.6B/'\n",
    "embeddings_index = {}\n",
    "f = open(os.path.join(glove_dir, 'glove.6B.100d.txt'))\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 100\n",
    "embedding_matrix = np.zeros((max_words, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    if i < max_words:\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential_2\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_3 (Embedding)      (None, 100, 100)          1000000   \n_________________________________________________________________\nflatten_2 (Flatten)          (None, 10000)             0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 32)                320032    \n_________________________________________________________________\ndense_3 (Dense)              (None, 1)                 33        \n=================================================================\nTotal params: 1,320,065\nTrainable params: 1,320,065\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Flatten, Dense\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_words, embedding_dim, input_length=maxlen))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[0].set_weights([embedding_matrix])\n",
    "model.layers[0].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train on 200 samples, validate on 10000 samples\nEpoch 1/10\n200/200 [==============================] - 1s 4ms/step - loss: 1.7158 - acc: 0.5200 - val_loss: 0.7377 - val_acc: 0.5022\nEpoch 2/10\n200/200 [==============================] - 1s 4ms/step - loss: 0.5928 - acc: 0.6600 - val_loss: 0.6857 - val_acc: 0.5502\nEpoch 3/10\n200/200 [==============================] - 1s 4ms/step - loss: 0.3852 - acc: 0.8800 - val_loss: 0.7560 - val_acc: 0.5133\nEpoch 4/10\n200/200 [==============================] - 1s 4ms/step - loss: 0.4107 - acc: 0.8200 - val_loss: 0.7439 - val_acc: 0.5303\nEpoch 5/10\n200/200 [==============================] - 1s 4ms/step - loss: 0.2218 - acc: 0.9450 - val_loss: 0.8130 - val_acc: 0.5246\nEpoch 6/10\n200/200 [==============================] - 1s 4ms/step - loss: 0.1554 - acc: 0.9750 - val_loss: 0.7731 - val_acc: 0.5517\nEpoch 7/10\n200/200 [==============================] - 1s 4ms/step - loss: 0.1322 - acc: 0.9600 - val_loss: 0.7696 - val_acc: 0.5519\nEpoch 8/10\n200/200 [==============================] - 1s 4ms/step - loss: 0.0538 - acc: 1.0000 - val_loss: 1.1138 - val_acc: 0.5101\nEpoch 9/10\n200/200 [==============================] - 1s 4ms/step - loss: 0.3089 - acc: 0.8500 - val_loss: 0.7413 - val_acc: 0.5716\nEpoch 10/10\n200/200 [==============================] - 1s 4ms/step - loss: 0.0310 - acc: 1.0000 - val_loss: 0.7880 - val_acc: 0.5631\n"
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['acc'])\n",
    "history = model.fit(x_train, y_train,epochs=10,batch_size=32,validation_data=(x_val, y_val))\n",
    "model.save_weights('pre_trained_glove_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is only a dense model to practice embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential_3\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_4 (Embedding)      (None, 100, 100)          1000000   \n_________________________________________________________________\nflatten_3 (Flatten)          (None, 10000)             0         \n_________________________________________________________________\ndense_4 (Dense)              (None, 32)                320032    \n_________________________________________________________________\ndense_5 (Dense)              (None, 1)                 33        \n=================================================================\nTotal params: 1,320,065\nTrainable params: 1,320,065\nNon-trainable params: 0\n_________________________________________________________________\nTrain on 200 samples, validate on 10000 samples\nEpoch 1/10\n200/200 [==============================] - 1s 4ms/step - loss: 0.6948 - acc: 0.4600 - val_loss: 0.6979 - val_acc: 0.5033\nEpoch 2/10\n200/200 [==============================] - 1s 4ms/step - loss: 0.5111 - acc: 0.9700 - val_loss: 0.6927 - val_acc: 0.5226\nEpoch 3/10\n200/200 [==============================] - 1s 4ms/step - loss: 0.2836 - acc: 1.0000 - val_loss: 0.7029 - val_acc: 0.5128\nEpoch 4/10\n200/200 [==============================] - 1s 4ms/step - loss: 0.1281 - acc: 0.9950 - val_loss: 0.7077 - val_acc: 0.5157\nEpoch 5/10\n200/200 [==============================] - 1s 4ms/step - loss: 0.0592 - acc: 1.0000 - val_loss: 0.7092 - val_acc: 0.5213\nEpoch 6/10\n200/200 [==============================] - 1s 4ms/step - loss: 0.0313 - acc: 1.0000 - val_loss: 0.7118 - val_acc: 0.5249\nEpoch 7/10\n200/200 [==============================] - 1s 4ms/step - loss: 0.0176 - acc: 1.0000 - val_loss: 0.7171 - val_acc: 0.5224\nEpoch 8/10\n200/200 [==============================] - 1s 4ms/step - loss: 0.0100 - acc: 1.0000 - val_loss: 0.7303 - val_acc: 0.5192\nEpoch 9/10\n200/200 [==============================] - 1s 4ms/step - loss: 0.0060 - acc: 1.0000 - val_loss: 0.7290 - val_acc: 0.5243\nEpoch 10/10\n200/200 [==============================] - 1s 4ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.7378 - val_acc: 0.5232\n"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Flatten, Dense\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_words, embedding_dim, input_length=maxlen))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()\n",
    "model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['acc'])\n",
    "history = model.fit(x_train, y_train,epochs=10,batch_size=32,validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {}
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = os.path.join(imdb_dir, 'test')\n",
    "labels = []\n",
    "texts = []\n",
    "for label_type in ['neg', 'pos']:\n",
    "    dir_name = os.path.join(test_dir, label_type)\n",
    "    for fname in sorted(os.listdir(dir_name)):\n",
    "        if fname[-4:] == '.txt':\n",
    "            f = open(os.path.join(dir_name, fname))\n",
    "            texts.append(f.read())\n",
    "            f.close()\n",
    "            if label_type == 'neg':\n",
    "                labels.append(0)\n",
    "            else:\n",
    "                labels.append(1)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "x_test = pad_sequences(sequences, maxlen=maxlen)\n",
    "y_test = np.asarray(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "25000/25000 [==============================] - 2s 70us/step\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[0.7896018857383728, 0.5659199953079224]"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "model.load_weights('pre_trained_glove_model.h5')\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "I love this movie\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[0.63107806],\n       [0.6336722 ],\n       [0.49351135],\n       [0.5613501 ],\n       [0.49946848],\n       [0.49946848],\n       [0.49946848],\n       [0.49946848],\n       [0.49946848],\n       [0.49946848],\n       [0.49946848],\n       [0.49946848],\n       [0.49946848],\n       [0.49946848],\n       [0.49946848],\n       [0.49946848],\n       [0.49946848],\n       [0.49946848],\n       [0.49946848],\n       [0.49946848],\n       [0.49946848],\n       [0.49946848],\n       [0.49946848],\n       [0.49946848],\n       [0.49946848],\n       [0.49946848],\n       [0.49946848],\n       [0.49946848],\n       [0.49946848],\n       [0.49946848],\n       [0.49946848],\n       [0.49946848],\n       [0.49946848],\n       [0.49946848],\n       [0.49946848],\n       [0.49946848],\n       [0.49946848],\n       [0.49946848],\n       [0.49946848],\n       [0.49946848],\n       [0.49946848],\n       [0.49946848],\n       [0.49946848],\n       [0.49946848],\n       [0.49946848],\n       [0.49946848],\n       [0.49946848],\n       [0.49946848],\n       [0.49946848],\n       [0.49946848],\n       [0.49946848],\n       [0.49946848],\n       [0.49946848],\n       [0.49946848],\n       [0.49946848],\n       [0.49946848],\n       [0.49946848],\n       [0.49946848],\n       [0.49946848],\n       [0.49946848],\n       [0.49946848],\n       [0.49946848],\n       [0.49946848],\n       [0.49946848],\n       [0.49946848],\n       [0.49946848],\n       [0.49946848],\n       [0.49946848],\n       [0.49946848],\n       [0.49946848],\n       [0.49946848],\n       [0.49946848],\n       [0.49946848],\n       [0.49946848],\n       [0.49946848],\n       [0.49946848],\n       [0.49946848],\n       [0.49946848],\n       [0.49946848],\n       [0.49946848],\n       [0.49946848],\n       [0.49946848],\n       [0.49946848],\n       [0.49946848],\n       [0.49946848],\n       [0.49946848],\n       [0.49946848],\n       [0.49946848],\n       [0.49946848],\n       [0.49946848],\n       [0.49946848],\n       [0.49946848],\n       [0.49946848],\n       [0.49946848],\n       [0.49946848],\n       [0.49946848],\n       [0.49946848],\n       [0.49946848],\n       [0.49946848],\n       [0.49946848]], dtype=float32)"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "data = []\n",
    "for i in range(100):\n",
    "    data.append('')\n",
    "data[0] = \"I love this movie\"\n",
    "data[1] = \"I really love this movie\"\n",
    "data[2] = \"This movie really sucks\"\n",
    "data[3] = \"What I saw...... I cannot get what it wants to say\"\n",
    "print((data[0]))\n",
    "sequences = tokenizer.texts_to_sequences(data)\n",
    "data = pad_sequences(sequences, maxlen=maxlen,)\n",
    "indices = np.arange(data.shape[0])\n",
    "data = data[indices]\n",
    "\n",
    "model.predict(data)\n",
    "#print(sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy implementation of a simple RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "timesteps = 100\n",
    "input_features = 32\n",
    "output_features = 64\n",
    "inputs = np.random.random((timesteps, input_features))\n",
    "state_t = np.zeros((output_features,))\n",
    "W = np.random.random((output_features, input_features))\n",
    "U = np.random.random((output_features, output_features))\n",
    "b = np.random.random((output_features,))\n",
    "successive_outputs = []\n",
    "for input_t in inputs:\n",
    "    output_t = np.tanh(np.dot(W, input_t) + np.dot(U, state_t) + b)\n",
    "    successive_outputs.append(output_t)\n",
    "    state_t = output_t\n",
    "final_output_sequence = np.concatenate(successive_outputs, axis=0)"
   ]
  }
 ]
}